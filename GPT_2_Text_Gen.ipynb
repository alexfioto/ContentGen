{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GPT-2-Text-Gen",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H7LoMj4GA4n_",
        "colab_type": "text"
      },
      "source": [
        "#  Train a GPT-2 Text-Generating Model w/ GPU For Free \n",
        "\n",
        "by [Max Woolf](http://minimaxir.com)\n",
        "\n",
        "*Last updated: November 10th, 2019*\n",
        "\n",
        "Retrain an advanced text generating neural network on any text dataset **for free on a GPU using Collaboratory** using `gpt-2-simple`!\n",
        "\n",
        "For more about `gpt-2-simple`, you can visit [this GitHub repository](https://github.com/minimaxir/gpt-2-simple). You can also read my [blog post](https://minimaxir.com/2019/09/howto-gpt2/) for more information how to use this notebook!\n",
        "\n",
        "\n",
        "To get started:\n",
        "\n",
        "1. Copy this notebook to your Google Drive to keep it and save your changes. (File -> Save a Copy in Drive)\n",
        "2. Make sure you're running the notebook in Google Chrome.\n",
        "3. Run the cells below:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KBkpRgBCBS2_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "7240ccc1-0755-4be1-e726-034abcfb6922"
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "!pip install -q gpt-2-simple\n",
        "import gpt_2_simple as gpt2\n",
        "from datetime import datetime\n",
        "from google.colab import files"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n",
            "  Building wheel for gpt-2-simple (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bj2IJLHP3KwE",
        "colab_type": "text"
      },
      "source": [
        "## GPU\n",
        "\n",
        "Colaboratory uses either a Nvidia T4 GPU or an Nvidia K80 GPU. The T4 is slightly faster than the old K80 for training GPT-2, and has more memory allowing you to train the larger GPT-2 models and generate more text.\n",
        "\n",
        "You can verify which GPU is active by running the cell below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sUmTooTW3osf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "d403c032-6d96-4766-efb0-665b75bbf748"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mon Sep 21 00:02:17 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 450.66       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   40C    P0    29W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0wXB05bPDYxS",
        "colab_type": "text"
      },
      "source": [
        "## Downloading GPT-2\n",
        "\n",
        "If you're retraining a model on new text, you need to download the GPT-2 model first. \n",
        "\n",
        "There are three released sizes of GPT-2:\n",
        "\n",
        "* `124M` (default): the \"small\" model, 500MB on disk.\n",
        "* `355M`: the \"medium\" model, 1.5GB on disk.\n",
        "* `774M`: the \"large\" model, cannot currently be finetuned with Colaboratory but can be used to generate text from the pretrained model (see later in Notebook)\n",
        "* `1558M`: the \"extra large\", true model. Will not work if a K80 GPU is attached to the notebook. (like `774M`, it cannot be finetuned).\n",
        "\n",
        "Larger models have more knowledge, but take longer to finetune and longer to generate text. You can specify which base model to use by changing `model_name` in the cells below.\n",
        "\n",
        "The next cell downloads it from Google Cloud Storage and saves it in the Colaboratory VM at `/models/<model_name>`.\n",
        "\n",
        "This model isn't permanently saved in the Colaboratory VM; you'll have to redownload it if you want to retrain it at a later time."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8wSlgXoDPCR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "24167b14-4a74-4e9a-b741-8338991db4d1"
      },
      "source": [
        "gpt2.download_gpt2(model_name=\"355M\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fetching checkpoint: 1.05Mit [00:00, 582Mit/s]                                                      \n",
            "Fetching encoder.json: 1.05Mit [00:00, 88.3Mit/s]                                                   \n",
            "Fetching hparams.json: 1.05Mit [00:00, 669Mit/s]                                                    \n",
            "Fetching model.ckpt.data-00000-of-00001: 1.42Git [00:09, 153Mit/s]                                  \n",
            "Fetching model.ckpt.index: 1.05Mit [00:00, 505Mit/s]                                                \n",
            "Fetching model.ckpt.meta: 1.05Mit [00:00, 150Mit/s]                                                 \n",
            "Fetching vocab.bpe: 1.05Mit [00:00, 205Mit/s]                                                       \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N8KXuKWzQSsN",
        "colab_type": "text"
      },
      "source": [
        "## Mounting Google Drive\n",
        "\n",
        "The best way to get input text to-be-trained into the Colaboratory VM, and to get the trained model *out* of Colaboratory, is to route it through Google Drive *first*.\n",
        "\n",
        "Running this cell (which will only work in Colaboratory) will mount your personal Google Drive in the VM, which later cells can use to get data in/out. (it will ask for an auth code; that auth is not saved anywhere)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "puq4iC6vUAHc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "086a9a4b-0b64-436f-9c44-f4c823d35d3a"
      },
      "source": [
        "gpt2.mount_gdrive()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BT__brhBCvJu",
        "colab_type": "text"
      },
      "source": [
        "## Uploading a Text File to be Trained to Colaboratory\n",
        "\n",
        "In the Colaboratory Notebook sidebar on the left of the screen, select *Files*. From there you can upload files:\n",
        "\n",
        "![alt text](https://i.imgur.com/TGcZT4h.png)\n",
        "\n",
        "Upload **any smaller text file**  (<10 MB) and update the file name in the cell below, then run the cell."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6OFnPCLADfll",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "file_name = \"showerthoughts.txt\""
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HeeSKtNWUedE",
        "colab_type": "text"
      },
      "source": [
        "If your text file is larger than 10MB, it is recommended to upload that file to Google Drive first, then copy that file from Google Drive to the Colaboratory VM."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Z6okFD8VKtS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gpt2.copy_file_from_gdrive(file_name)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LdpZQXknFNY3",
        "colab_type": "text"
      },
      "source": [
        "## Finetune GPT-2\n",
        "\n",
        "The next cell will start the actual finetuning of GPT-2. It creates a persistent TensorFlow session which stores the training config, then runs the training for the specified number of `steps`. (to have the finetuning run indefinitely, set `steps = -1`)\n",
        "\n",
        "The model checkpoints will be saved in `/checkpoint/run1` by default. The checkpoints are saved every 500 steps (can be changed) and when the cell is stopped.\n",
        "\n",
        "The training might time out after 4ish hours; make sure you end training and save the results so you don't lose them!\n",
        "\n",
        "**IMPORTANT NOTE:** If you want to rerun this cell, **restart the VM first** (Runtime -> Restart Runtime). You will need to rerun imports but not recopy files.\n",
        "\n",
        "Other optional-but-helpful parameters for `gpt2.finetune`:\n",
        "\n",
        "\n",
        "*  **`restore_from`**: Set to `fresh` to start training from the base GPT-2, or set to `latest` to restart training from an existing checkpoint.\n",
        "* **`sample_every`**: Number of steps to print example output\n",
        "* **`print_every`**: Number of steps to print training progress.\n",
        "* **`learning_rate`**:  Learning rate for the training. (default `1e-4`, can lower to `1e-5` if you have <1MB input data)\n",
        "*  **`run_name`**: subfolder within `checkpoint` to save the model. This is useful if you want to work with multiple models (will also need to specify  `run_name` when loading the model)\n",
        "* **`overwrite`**: Set to `True` if you want to continue finetuning an existing model (w/ `restore_from='latest'`) without creating duplicate copies. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aeXshJM-Cuaf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "dae11b60-64ee-4f00-e557-08df4b50dcde"
      },
      "source": [
        "sess = gpt2.start_tf_sess()\n",
        "\n",
        "gpt2.finetune(sess,\n",
        "              dataset=file_name,\n",
        "              model_name='355M',\n",
        "              steps=2000,\n",
        "              restore_from='fresh',\n",
        "              run_name='run1',\n",
        "              print_every=10,\n",
        "              sample_every=200,\n",
        "              save_every=500\n",
        "              )"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/gpt_2_simple/src/sample.py:17: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/gpt_2_simple/src/memory_saving_gradients.py:62: get_backward_walk_ops (from tensorflow.contrib.graph_editor.select) is deprecated and will be removed after 2019-06-06.\n",
            "Instructions for updating:\n",
            "Please use tensorflow.python.ops.op_selector.get_backward_walk_ops.\n",
            "Loading checkpoint models/355M/model.ckpt\n",
            "INFO:tensorflow:Restoring parameters from models/355M/model.ckpt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loading dataset...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:05<00:00,  5.30s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "dataset has 1187556 tokens\n",
            "Training...\n",
            "[10 | 17.78] loss=2.21 avg=2.21\n",
            "[20 | 26.58] loss=2.29 avg=2.25\n",
            "[30 | 35.38] loss=1.98 avg=2.16\n",
            "[40 | 44.18] loss=2.09 avg=2.14\n",
            "[50 | 52.98] loss=1.77 avg=2.07\n",
            "[60 | 61.78] loss=2.05 avg=2.06\n",
            "[70 | 70.57] loss=2.03 avg=2.06\n",
            "[80 | 79.37] loss=2.20 avg=2.08\n",
            "[90 | 88.17] loss=2.05 avg=2.07\n",
            "[100 | 96.97] loss=1.88 avg=2.05\n",
            "[110 | 105.76] loss=1.94 avg=2.04\n",
            "[120 | 114.57] loss=1.93 avg=2.03\n",
            "[130 | 123.37] loss=1.72 avg=2.01\n",
            "[140 | 132.21] loss=1.99 avg=2.01\n",
            "[150 | 141.01] loss=2.27 avg=2.03\n",
            "[160 | 149.81] loss=2.27 avg=2.04\n",
            "[170 | 158.61] loss=2.13 avg=2.05\n",
            "[180 | 167.41] loss=1.97 avg=2.04\n",
            "[190 | 176.21] loss=1.90 avg=2.03\n",
            "[200 | 185.01] loss=1.89 avg=2.03\n",
            "======== SAMPLE 1 ========\n",
            " are the same color and there is no difference between the color.<|endoftext|>\"\n",
            "\"<|startoftext|>I wonder how many girls in the world want a penis.<|endoftext|>\"\n",
            "\"<|startoftext|>There will be an infinite number of animals with names like \"mammoth\" and \"crocodile\", but no one will call them \"crocodile\".<|endoftext|>\"\n",
            "\"<|startoftext|>When we're on moon, we're looking at Venus, Venus, Venus, Venus, Venus, Venus, and Venus, but no one will call them Venus, Venus, Venus, Venus, Venus, Venus, Venus, Venus, Venus, Venus, Venus, Venus, Venus, Venus, and Venus, because people think we're talking about Venus.<|endoftext|>\"\n",
            "\"<|startoftext|>If we were on a moon , we're looking at Venus, Venus, Venus, Venus, Venus, Venus, Venus, Venus, Venus, and Venus, but there will be no name for the name Venus, Venus, Venus, Venus, Venus, Venus, Venus, Venus, Venus, Venus, Venus, and Venus, because people think we're talking about Venus.<|endoftext|>\"\n",
            "\"<|startoftext|>When we're on the moon, we're looking at Venus, Venus, Venus, Venus, Venus, Venus, Venus, Venus, Venus, and Venus, and we're talking about Venus, Venus, Venus, Venus, Venus, Venus, Venus, Venus, Venus, Venus, Venus, Venus, Venus, Venus, Venus, Venus, and Venus, but there will be no name for the name Venus, Venus, Venus, Venus, Venus, Venus, Venus, Venus, Venus, Venus, and Venus, because people think we're talking about Venus.<|endoftext|>\"\n",
            "\"<|startoftext|>If we were on a moon , we're talking about Venus, Venus, Venus, Venus, Venus, Venus, Venus, Venus, Venus, Venus, Venus, and Venus, but there will be no name for the name Venus, Venus, Venus, Venus, Venus, Venus, Venus, Venus, Venus, Venus, Venus, Venus, Venus, Venus, Venus, Venus, Venus, Venus, Venus, Venus, Venus, Venus, Venus, Venus, and Venus for no reason, or at a very inconvenient time.<|endoftext|>\"\n",
            "\"<|startoftext|>Why is it that people hate us, but the same people hate us, when we are good at something, yet refuse to do the same thing, yet we are the best at that thing<|endoftext|>\"\n",
            "\"<|startoftext|>If a guy with a penis had been having intercourse with someone with a vagina, he would have had a very small dick by now<|endoftext|>\"\n",
            "\"<|startoftext|>It's actually possible to give a guy a penis and another someone a vagina while he is having intercourse with them (both) at the same time, but that would be a lot of bad things.<|endoftext|>\"\n",
            "\"<|startoftext|>We are probably only able to see the planet Venus through binoculars with telescopes.<|endoftext|>\"\n",
            "\"<|startoftext|>When there is a huge group of girls in the world, there will be an infinite number of animals who will have the names of their name 'Venus' and 'Crocodile', but no one will call them 'Crocodile', 'Venus', or 'Crocodile'.<|endoftext|>\"\n",
            "\"<|startoftext|>A lot of people will hate us , but the same people will hate us when we are good at something.<|endoftext|>\"\n",
            "\"<|startoftext|>If you are a kid in an adult, or a young adult, you've probably just been told a bunch of really mean things in your adult life.<|endoftext|>\"\n",
            "\"<|startoftext|>A few people will hate us, but the same people will hate us when we are good at something<|endoftext|>\"\n",
            "\"<|startoftext|>I think we're not born and died in this life, we just live and die in our parent's life.<|endoftext|>\"\n",
            "\"<|startoftext|>I know, but I wonder if there's a lot of stupid stuff in the past that will be talked about and will actually be a good thing in the future.<|endoftext|>\"\n",
            "\"<|startoftext|>What if when we are in the future we could be in an adult or a young adult, and some really dumb stuff could be talked\n",
            "\n",
            "[210 | 212.18] loss=1.62 avg=2.01\n",
            "[220 | 220.99] loss=1.81 avg=2.00\n",
            "[230 | 229.79] loss=1.95 avg=1.99\n",
            "[240 | 238.59] loss=1.94 avg=1.99\n",
            "[250 | 247.39] loss=1.56 avg=1.97\n",
            "[260 | 256.20] loss=1.80 avg=1.96\n",
            "[270 | 265.00] loss=1.83 avg=1.96\n",
            "[280 | 273.81] loss=1.80 avg=1.95\n",
            "[290 | 282.61] loss=2.07 avg=1.96\n",
            "[300 | 291.42] loss=2.11 avg=1.96\n",
            "[310 | 300.22] loss=1.72 avg=1.95\n",
            "[320 | 309.03] loss=1.78 avg=1.95\n",
            "[330 | 317.84] loss=1.69 avg=1.94\n",
            "[340 | 326.64] loss=2.11 avg=1.94\n",
            "[350 | 335.44] loss=2.04 avg=1.95\n",
            "[360 | 344.25] loss=1.90 avg=1.95\n",
            "[370 | 353.05] loss=1.85 avg=1.94\n",
            "[380 | 361.85] loss=1.82 avg=1.94\n",
            "[390 | 370.65] loss=1.91 avg=1.94\n",
            "[400 | 379.45] loss=1.59 avg=1.93\n",
            "======== SAMPLE 1 ========\n",
            "\n",
            "of<|startoftext|>No One Will Ever Know<|endoftext|>\"\n",
            "\"<|startoftext|>It is not so strange that people that are overweight or obese have more children than the normal people<|endoftext|>\"\n",
            "\"<|startoftext|>People who wear face masks probably know more secrets than we do about them and how to avoid them then we do about something.<|endoftext|>\"\n",
            "\"<|startoftext|>Polarizing the sun is the worst thing you can do to earth but polarizing Mars also is horrible. Mars doesn't need the sun to become habitable. That's all. So it’s kinda just a waste.<|endoftext|>\"\n",
            "\"<|startoftext|>When looking for a place to go out, don't think \"this is the coolest place I have ever been\" think of it’s own coolness.<|endoftext|>\"\n",
            "\"<|startoftext|>This year has caused us to start looking forward, thinking about our futures, not to mention our past years.<|endoftext|>\"\n",
            "\"<|startoftext|>Asking someone else for a password on their computer is kind of like asking for a password on someone else's laptop, you either get it or you dont.<|endoftext|>\"\n",
            "\"<|startoftext|>There’s a lot of people who will be the first to hear your death, no one will be the second one.<|endoftext|>\"\n",
            "\"<|startoftext|>A cat that has a very specific pattern is a cat with the name Kitty<|endoftext|>\"\n",
            "\"<|startoftext|>We should just turn our entire world upside down and see if people have any thoughts on that. The world would be so different!<|endoftext|>\"\n",
            "\"<|startoftext|>Bubbles is like a fish out of water for our planet Earth. It’s a miracle that Bubble is still around.<|endoftext|>\"\n",
            "\"<|startoftext|>The word “black” has just appeared on a post titled “We’re not racist”.<|endoftext|>\"\n",
            "\"<|startoftext|>When talking to people about money you really just want to hear the average person that isn't on the list but you know are talking to the millionaire.<|endoftext|>\"\n",
            "\"<|startoftext|>Polarizing the sun has the opposite effect of polarizing Mars. Mars is a waste like that. We should just turn all our universe upside down and see if people have any thoughts on that.<|endoftext|>\"\n",
            "\"<|startoftext|>There’s a lot of people will be the first to hear your death, no one will be the second one. Just as importantly there's a lot of people that haven’t thought the first one.<|endoftext|>\"\n",
            "\"<|startoftext|>If you can talk to a person about money they might just be telling you more about money.<|endoftext|>\"\n",
            "\"<|startoftext|>Asking someone else for a password on a computer is kinda like asking someone else for a password on a person else's laptop.<|endoftext|>\"\n",
            "\"<|startoftext|>If you're not having fun then you shouldn't spend time in the shower.<|endoftext|>\"\n",
            "\"<|startoftext|>It is so strange that people that are overweight or obese just have more children compared to the other people. It kind of feels like there's an eternity in which there's one.<|endoftext|>\"\n",
            "\"<|startoftext|>What if we're not our real selves?<|endoftext|>\"\n",
            "\"<|startoftext|>If the Bible was invented and then destroyed, would the internet become just another hoax?<|endoftext|>\"\n",
            "\"<|startoftext|>The first person to invent the internet and the first person to find it, are basically the same people, right?<|endoftext|>\"\n",
            "\"<|startoftext|>The term “black” has never been called after a gender connotation<|endoftext|>\"\n",
            "\"<|startoftext|>If our real selves are not our real selves, and our real selves have never been real and our fake selves are, then we need an afterlife.<|endoftext|>\"\n",
            "\"<|startoftext|>This is just one of those situations when we should just turn our entire world upside down and see if we have any thoughts on that. The world would be so different!<|endoftext|\n",
            "\n",
            "[410 | 404.12] loss=2.05 avg=1.93\n",
            "[420 | 412.92] loss=1.53 avg=1.92\n",
            "[430 | 421.73] loss=1.96 avg=1.92\n",
            "[440 | 430.53] loss=1.96 avg=1.92\n",
            "[450 | 439.35] loss=1.93 avg=1.92\n",
            "[460 | 448.18] loss=2.34 avg=1.93\n",
            "[470 | 456.98] loss=2.02 avg=1.94\n",
            "[480 | 465.77] loss=1.72 avg=1.93\n",
            "[490 | 474.58] loss=1.79 avg=1.93\n",
            "[500 | 483.38] loss=2.18 avg=1.93\n",
            "Saving checkpoint/run1/model-500\n",
            "[510 | 498.90] loss=2.08 avg=1.94\n",
            "[520 | 507.70] loss=1.31 avg=1.92\n",
            "[530 | 516.50] loss=1.87 avg=1.92\n",
            "[540 | 525.30] loss=1.74 avg=1.92\n",
            "[550 | 534.11] loss=1.81 avg=1.91\n",
            "[560 | 542.91] loss=1.96 avg=1.91\n",
            "[570 | 551.71] loss=2.18 avg=1.92\n",
            "[580 | 560.50] loss=2.08 avg=1.92\n",
            "[590 | 569.31] loss=1.61 avg=1.92\n",
            "[600 | 578.11] loss=2.04 avg=1.92\n",
            "======== SAMPLE 1 ========\n",
            "mare.<|endoftext|>\"\n",
            "\"<|startoftext|>Every day is the worst day there ever was<|endoftext|>\"\n",
            "\"<|startoftext|>It's 2017.<|endoftext|>\"\n",
            "\"<|startoftext|>If you can do it, you can do it better.<|endoftext|>\"\n",
            "\"<|startoftext|>The only good feeling you'll get out of dying is watching your loved ones enjoy the life you once had in their last breaths.<|endoftext|>\"\n",
            "\"<|startoftext|>Mental illness isn’t terminal depression, it’s depression caused by depression.<|endoftext|>\"\n",
            "\"<|startoftext|>Being sick and feeling you are not strong enough are the same feelings as being overweight<|endoftext|>\"\n",
            "\"<|startoftext|>One day you'll think that is someone you love, your closest friend, and that you like the person you think you’re attracted to. The next you'll think for yourselves to decide who you want to be.<|endoftext|>\"\n",
            "\"<|startoftext|>If you think about it, being sick and feeling you’re not strong enough is the same feeling as being overweight.<|endoftext|>\"\n",
            "\"<|startoftext|>Why is my phone not on my pocket or my phone? irl<|endoftext|>\"\n",
            "\"<|startoftext|>If you don’t get a high with that person, then he's just a great guy.<|endoftext|>\"\n",
            "\"<|startoftext|>If you see a UFO over your head, you’re a very lucky person.<|endoftext|>\"\n",
            "\"<|startoftext|>We are witnessing the beginning of the end for the human race. Humanity was only a few years away from extinction, and we are slowly coming back online like never before and some of us already have our memories wiped. The only good feeling you'll get on dying is watching your loved ones enjoy the life you were able to have in their last breaths.<|endoftext|>\"\n",
            "\"<|startoftext|>Being sick and feeling you aren’t strong enough is the same feelings as being overweight.<|endoftext|>\"\n",
            "\"<|startoftext|>People will look back on you to this day and think \"Why were you so terrible?\"<|endoftext|>\"\n",
            "\"<|startoftext|>If someone is allergic, is it possible to just go to the bathroom after and avoid the discomfort<|endoftext|>\"\n",
            "\"<|startoftext|>If you die in a car crash, it’s not death. It’s just a new vehicle. What I call death, I would call a new car a highway.<|endoftext|>\"\n",
            "\"<|startoftext|>What was the first thought that made you realize you’re not real<|endoftext|>\"\n",
            "\"<|startoftext|>We think in terms of ideas/narratives/etc., but that’s how most people find out about entertainment.<|endoftext|>\"\n",
            "\"<|startoftext|>If you read through a post, it takes you a second or longer to realize I’m not posting in that category<|endoftext|>\"\n",
            "\"<|startoftext|>A friend was a great babysitter, and a great friend, then they were a great babysitter/good friend, and then they were never friends again.<|endoftext|>\"\n",
            "\"<|startoftext|>People who get good at puzzle will probably never get to solve their own ones<|endoftext|>\"\n",
            "\"<|startoftext|>Most men are circumcised when they are younger, because circumcision didn’t exist before people were made. And the reason why? Because people were afraid of the unknown, and now people fear of the unknown<|endoftext|>\"\n",
            "\"<|startoftext|>The only good feeling you'll get out of dying is watching your loved ones enjoy the life you once had in thier last breaths.<|endoftext|>\"\n",
            "\"<|startoftext|>The only good feeling you'll get out of dying is watching your loved ones enjoy the life you once had in thier last days.<|endoftext|>\"\n",
            "\"<|startoftext|>If we all shared the same birthday, wouldn't that be the day people called \"\"Happy Birthday!\"\"?<|endoftext|>\"\n",
            "\"<|startoftext|>I thought a lot of people thought about death more than life, but I’ve never\n",
            "\n",
            "[610 | 602.76] loss=1.05 avg=1.90\n",
            "[620 | 611.57] loss=1.99 avg=1.90\n",
            "[630 | 620.37] loss=2.08 avg=1.91\n",
            "[640 | 629.17] loss=1.85 avg=1.90\n",
            "[650 | 637.97] loss=1.85 avg=1.90\n",
            "[660 | 646.77] loss=1.78 avg=1.90\n",
            "[670 | 655.57] loss=1.96 avg=1.90\n",
            "[680 | 664.36] loss=2.02 avg=1.90\n",
            "[690 | 673.16] loss=1.55 avg=1.90\n",
            "[700 | 681.96] loss=1.63 avg=1.89\n",
            "[710 | 690.76] loss=1.50 avg=1.88\n",
            "[720 | 699.57] loss=1.23 avg=1.87\n",
            "[730 | 708.36] loss=2.06 avg=1.88\n",
            "[740 | 717.16] loss=2.02 avg=1.88\n",
            "[750 | 725.97] loss=1.92 avg=1.88\n",
            "[760 | 734.77] loss=1.91 avg=1.88\n",
            "[770 | 743.56] loss=1.62 avg=1.87\n",
            "[780 | 752.39] loss=1.78 avg=1.87\n",
            "[790 | 761.21] loss=1.94 avg=1.87\n",
            "[800 | 770.01] loss=1.62 avg=1.87\n",
            "======== SAMPLE 1 ========\n",
            "oftext|>\"\n",
            "\"<|startoftext|>We are a group of human beings that we've created, and the reason why we are such a group is because of the things that we've created<|endoftext|>\"\n",
            "\"<|startoftext|>If the name 'Bathroom' was removed, you'd still have a shower.<|endoftext|>\"\n",
            "\"<|startoftext|>Your name is what makes your hair stand on end<|endoftext|>\"\n",
            "\"<|startoftext|>If a video is the 'best' at what happens in a movie, is it even the best at what happens?<|endoftext|>\"\n",
            "\"<|startoftext|>The reason why we create a group and call it 'human' is so because of the things that we have created<|endoftext|>\"\n",
            "\"<|startoftext|>I got off to a great start to the year<|endoftext|>\"\n",
            "\"<|startoftext|>The best thing about 2017 is the human species is still figuring out what to do<|endoftext|>\"\n",
            "\"<|startoftext|>The only bad thing about 2017 is the human species is still figuring out what to do<|endoftext|>\"\n",
            "\"<|startoftext|>If the name Bathroom was removed, you'd still have a shower.<|endoftext|>\"\n",
            "\"<|startoftext|>You're closer to reaching a house than you ever have been in your life.<|endoftext|>\"\n",
            "\"<|startoftext|>What if the name 'Bathroom' was removed, but the name was changed to 'Human'?<|endoftext|>\"\n",
            "\"<|startoftext|>What if the name Bathroom was removed, but the name was changed to the name ?!<|endoftext|>\"\n",
            "\"<|startoftext|>People who were told they’re good when you speak, can still be a jerk if you are bad, but they are no closer to you than they are with the person.<|endoftext|>\"\n",
            "\"<|startoftext|>If I give you a choice of whether to believe in God, and politics is real, what would you do?<|endoftext|>\"\n",
            "\"<|startoftext|>What if the name Bathroom was changed to Human?<|endoftext|>\"\n",
            "\"<|startoftext|>The fact that the whole world is so interconnected that we don't really understand one another. Is a good thing. Because then we could see that everyone’s lives depend on their thoughts. Not all thought are good. Some thought are good. All thought are good. But for some, the thought they gave me is the good thing.<|endoftext|>\"\n",
            "\"<|startoftext|>You may be seeing pictures of you that have disappeared in the future.<|endoftext|>\"\n",
            "\"<|startoftext|>Someday will people will just think you look like you<|endoftext|>\"\n",
            "\"<|startoftext|>The best looking guy you can hope to see is probably one of your mothers.<|endoftext|>\"\n",
            "\"<|startoftext|>You can never know what color your own eyes are<|endoftext|>\"\n",
            "\"<|startoftext|>Bathrooms are just sinks.<|endoftext|>\"\n",
            "\"<|startoftext|>What if the name Bathroom was changed to 'Human'?<|endoftext|>\"\n",
            "\"<|startoftext|>The best looking guy you can hope to see is probably your mother.<|endoftext|>\"\n",
            "\"<|startoftext|>Someday people will think you look like you<|endoftext|>\"\n",
            "\"<|startoftext|>What if the name Bathroom was changed to Human?<|endoftext|>\"\n",
            "\"<|startoftext|>You can never know what color your own eyes are.<|endoftext|>\"\n",
            "\"<|startoftext|>You can never know what color your own eyes are.<|endoftext|>\"\n",
            "\"<|startoftext|>Bathrooms are just sinks.<|endoftext|>\"\n",
            "\"<|startoftext|>If someone were to use a sommelier, people would think they were a really good sommelier<|endoftext|>\"\n",
            "\"<|startoftext|>It takes a lot to make a computer a computer<|endoftext|>\"\n",
            "\"<|startoftext|>If a computer was an actual sentient being, it could probably run the human race for hours\n",
            "\n",
            "[810 | 794.62] loss=1.28 avg=1.86\n",
            "[820 | 803.42] loss=1.56 avg=1.85\n",
            "[830 | 812.22] loss=1.79 avg=1.85\n",
            "[840 | 821.02] loss=2.07 avg=1.86\n",
            "[850 | 829.82] loss=1.71 avg=1.85\n",
            "[860 | 838.62] loss=1.41 avg=1.85\n",
            "[870 | 847.42] loss=1.88 avg=1.85\n",
            "[880 | 856.23] loss=1.44 avg=1.84\n",
            "[890 | 865.03] loss=1.72 avg=1.84\n",
            "[900 | 873.82] loss=1.82 avg=1.84\n",
            "[910 | 882.62] loss=1.74 avg=1.84\n",
            "[920 | 891.42] loss=2.11 avg=1.84\n",
            "[930 | 900.21] loss=2.02 avg=1.84\n",
            "[940 | 909.01] loss=2.01 avg=1.85\n",
            "[950 | 917.82] loss=1.43 avg=1.84\n",
            "[960 | 926.62] loss=1.73 avg=1.84\n",
            "[970 | 935.41] loss=1.74 avg=1.84\n",
            "[980 | 944.21] loss=1.35 avg=1.83\n",
            "[990 | 953.01] loss=2.00 avg=1.83\n",
            "[1000 | 961.81] loss=1.70 avg=1.83\n",
            "Saving checkpoint/run1/model-1000\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/training/saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to delete files with this prefix.\n",
            "======== SAMPLE 1 ========\n",
            "\"<|startoftext|>Somebody has probably tried everything in this world, and still got cold, only to have a brain freeze for the life of the person they tried.<|endoftext|>\"\n",
            "\"<|startoftext|>In the next 10 years, there will be an increasing number of people asking their parents “What if” like us.<|endoftext|>\"\n",
            "\"<|startoftext|>Some of us might have been the last person to see each other's faces and be surprised our parents didn’t see us everytime.<|endoftext|>\"\n",
            "\"<|startoftext|>With every new technology the government creates, there’s an increasing chance that they’re the one creating the tech the future holds so we should expect more of the same.<|endoftext|>\"\n",
            "<|startoftext|>Youtube<|endoftext|>\n",
            "\"<|startoftext|>If we are all going to be internet veterans in a few decades, how will we remember some of the memories we’re trying to forget?<|endoftext|>\"\n",
            "\"<|startoftext|>Your name and home address are publicly displayed in a lot of products.<|endoftext|>\"\n",
            "\"<|startoftext|>A lot of people probably think we are all in one big family at their jobs...<|endoftext|>\"\n",
            "\"<|startoftext|>Since a lot of people have lost weight, there may be a group of people who are severely underweight.<|endoftext|>\"\n",
            "\"<|startoftext|>No real life player likes going to the bathroom alone, but it’s better than going in public without anyone<|endoftext|>\"\n",
            "\"<|startoftext|>It’s possible that in the distant future, as we age our eyes will eventually grow smaller so that we can’t see our eyeball when we go to the bathroom<|endoftext|>\"\n",
            "\"<|startoftext|>It's nice to get some sleep when the day is over, but it’s nice to get some sleep when the night is near.<|endoftext|>\"\n",
            "\"<|startoftext|>2020 is a cautionary tale on how well things can go wrong.<|endoftext|>\"\n",
            "\"<|startoftext|>It’s nice to get some sleep when the day is over, but it’s much better when the night is near.<|endoftext|>\"\n",
            "\"<|startoftext|>People with good reputations are rarely seen without masks<|endoftext|>\"\n",
            "\"<|startoftext|>There must be a very long line of people with really bad reputations who just quietly hang out with no one, waiting for a friend to show up.<|endoftext|>\"\n",
            "\"<|startoftext|>The worst thing about being single is that no one wants to date you<|endoftext|>\"\n",
            "\"<|startoftext|>The average number of feet per gallon is 0.3<|endoftext|>\"\n",
            "\"<|startoftext|>Dogs have never tasted what humans have made for them<|endoftext|>\"\n",
            "\"<|startoftext|>At the very least, we are safe from being able to use a gun at a gas station with a dead person.<|endoftext|>\"\n",
            "\"<|startoftext|>There’s no law against being single, but there’s a law against sleeping at a dead person’s bed.<|endoftext|>\"\n",
            "\"<|startoftext|>Somewhere, the time has passed the same place the person who recorded the last time was on the other side of the world.<|endoftext|>\"\n",
            "\"<|startoftext|>If you can't make an offer that you can't refuse, you can't refuse a friend<|endoftext|>\"\n",
            "\"<|startoftext|>There are probably millions of people out there who think the last time we dated was when we both had knee replacements.<|endoftext|>\"\n",
            "\"<|startoftext|>The fact that everyone’s age ranges from 8 to 100 indicates that there’s probably hundreds of millions of people out there who think their age range is anywhere from 8 to 100.<|endoftext|>\"\n",
            "\"<|startoftext|>The idea of not thinking about the negative has made most people very unhappy.<|endoftext|>\"\n",
            "\"<|startoftext|>Balls is a more common noun than legs.<|endoftext|>\"\n",
            "\"<|startoftext|>The internet\n",
            "\n",
            "[1010 | 993.74] loss=1.46 avg=1.82\n",
            "[1020 | 1002.54] loss=1.93 avg=1.83\n",
            "[1030 | 1011.35] loss=1.28 avg=1.82\n",
            "[1040 | 1020.16] loss=1.58 avg=1.81\n",
            "[1050 | 1028.97] loss=1.72 avg=1.81\n",
            "[1060 | 1037.78] loss=1.16 avg=1.80\n",
            "[1070 | 1046.58] loss=1.90 avg=1.80\n",
            "[1080 | 1055.38] loss=1.18 avg=1.79\n",
            "[1090 | 1064.21] loss=1.73 avg=1.79\n",
            "[1100 | 1073.02] loss=1.48 avg=1.79\n",
            "[1110 | 1081.82] loss=1.44 avg=1.78\n",
            "[1120 | 1090.62] loss=1.07 avg=1.77\n",
            "[1130 | 1099.42] loss=1.11 avg=1.76\n",
            "[1140 | 1108.21] loss=1.41 avg=1.76\n",
            "[1150 | 1117.01] loss=1.81 avg=1.76\n",
            "[1160 | 1125.80] loss=1.94 avg=1.76\n",
            "[1170 | 1134.60] loss=2.20 avg=1.77\n",
            "[1180 | 1143.40] loss=1.39 avg=1.76\n",
            "[1190 | 1152.19] loss=1.72 avg=1.76\n",
            "[1200 | 1160.99] loss=2.00 avg=1.76\n",
            "======== SAMPLE 1 ========\n",
            "startoftext|>If the whole world used real currency, the average person would be very wealthy.<|endoftext|>\"\n",
            "\"<|startoftext|>AIs from AI Dungeon 2 to sexy to funny and one based wholly on Reddit!<|endoftext|>\"\n",
            "\"<|startoftext|>If an alien world was visited by an alien species that could make good space invaders, they too would probably try to conquer us.<|endoftext|>\"\n",
            "\"<|startoftext|>If you can get off for an hour before your partner is ready then you are an incredibly long-term partner.<|endoftext|>\"\n",
            "\"<|startoftext|>What if the whole world used real currency, like coins.<|endoftext|>\"\n",
            "\"<|startoftext|>You think that you’re smart enough to be the first person to see your naked body and wonder if they think about your face everytime they look at you and think of your naked body<|endoftext|>\"\n",
            "\"<|startoftext|>The only reason you see the same things over and over again is to remember that you used to view those things differently.<|endoftext|>\"\n",
            "\"<|startoftext|>There really is no reason for the phrase, 'the mind flies'<|endoftext|>\"\n",
            "\"<|startoftext|>What if we got rid of all money.<|endoftext|>\"\n",
            "\"<|startoftext|>It is possible to create a universe that is completely alien and complete strangers to us without ever existing in a real world world.<|endoftext|>\"\n",
            "\"<|startoftext|>If someone has an alternate reality version of the same birthday than you, then there are two other people inside of you, right?<|endoftext|>\"\n",
            "\"<|startoftext|>Telling a guy \"\"don't worry about it\"\" in front of a chick could be interpreted as \"\"don't tell me you're a dick\"\"<|endoftext|>\"\n",
            "\"<|startoftext|>It's a shame that every time a random person gets laid in a video of a porno it’s always the girl in the video who stays out of it<|endoftext|>\"\n",
            "\"<|startoftext|>When you think about it, life is more like a simulation than the real thing.<|endoftext|>\"\n",
            "\"<|startoftext|>If you had a pet pig would have pig tattooed on you<|endoftext|>\"\n",
            "\"<|startoftext|>If you had a pet pig, would it be pig tatted or dyed<|endoftext|>\"\n",
            "\"<|startoftext|>It will still be fun to tell jokes in the future, but not to this year.<|endoftext|>\"\n",
            "\"<|startoftext|>You will have more fun playing golf if you are one of those rare people where you are actually ranked higher than anyone else.<|endoftext|>\"\n",
            "\"<|startoftext|>It will still be fun to tell jokes in the future, but not this year.<|endoftext|>\"\n",
            "\"<|startoftext|>If you guys did a cross-country road race it would be called a road race.<|endoftext|>\"\n",
            "\"<|startoftext|>AIs from AI Dungeon 2 to sexy to funny and one based wholly on Reddit!<|endoftext|>\"\n",
            "\"<|startoftext|>It will still be fun to tell jokes in the future, but not this year.<|endoftext|>\"\n",
            "\"<|startoftext|>I bet the world record for most people using the same phone without switching to another phone number is set on this year.<|endoftext|>\"\n",
            "\"<|startoftext|>If you guys did a cross-country road race would be called a road race?<|endoftext|>\"\n",
            "\"<|startoftext|>AIs from AI Dungeon 2 to sexy to funny and one based wholly on Reddit!<|endoftext|>\"\n",
            "\"<|startoftext|>Saying that a picture is worth a thousand words will now have the same effect as saying, \"\"What's your story?\"\"<|endoftext|>\"\n",
            "\"<|startoftext|>It's weird how in the movie ''The Matrix\"\" (A) The Matrix is The System, (B) The System is The Matrix, and (C) The System is A System.<|endoftext|>\"\n",
            "\"<|startoftext|>AIs from AI Dungeon 2 to sexy to funny and one based wholly on Reddit!<|endoftext|>\"\n",
            "\"<\n",
            "\n",
            "[1210 | 1185.66] loss=1.98 avg=1.77\n",
            "[1220 | 1194.46] loss=1.64 avg=1.77\n",
            "[1230 | 1203.25] loss=1.23 avg=1.76\n",
            "[1240 | 1212.05] loss=1.24 avg=1.75\n",
            "[1250 | 1220.84] loss=1.55 avg=1.75\n",
            "[1260 | 1229.64] loss=1.26 avg=1.74\n",
            "[1270 | 1238.44] loss=1.84 avg=1.74\n",
            "[1280 | 1247.24] loss=1.59 avg=1.74\n",
            "[1290 | 1256.04] loss=2.02 avg=1.74\n",
            "[1300 | 1264.84] loss=1.74 avg=1.74\n",
            "[1310 | 1273.64] loss=1.49 avg=1.74\n",
            "[1320 | 1282.44] loss=1.08 avg=1.73\n",
            "[1330 | 1291.23] loss=1.04 avg=1.72\n",
            "[1340 | 1300.03] loss=1.51 avg=1.72\n",
            "[1350 | 1308.83] loss=1.74 avg=1.72\n",
            "[1360 | 1317.63] loss=1.32 avg=1.71\n",
            "[1370 | 1326.42] loss=1.80 avg=1.72\n",
            "[1380 | 1335.23] loss=1.52 avg=1.71\n",
            "[1390 | 1344.03] loss=1.39 avg=1.71\n",
            "[1400 | 1352.83] loss=1.48 avg=1.71\n",
            "======== SAMPLE 1 ========\n",
            "oftext|>\"\n",
            "\"<|startoftext|>As a child you want to be big, strong, and bad. As a parent you want your kid to be tiny, tiny, and good. As a grandparent you want them to be nice, sweet, and kind. As an employee you want them to be happy and stay happy so you don't have to work for them.<|endoftext|>\"\n",
            "\"<|startoftext|>If he is in the right mind, Hitler was probably a horrible person who committed really awful crimes.<|endoftext|>\"\n",
            "\"<|startoftext|>Weird that on the reverse side of the coin the moon rises for those on the left to make that reverse side more interesting.<|endoftext|>\"\n",
            "\"<|startoftext|>Insecticidal maniacs would probably be the least of your worries if it weren't for the fact spiders were the closest thing to insects<|endoftext|>\"\n",
            "\"<|startoftext|>The phrase \"\"if you're good enough for me\"\" implies that if you aren't good enough to me, then I won't fuck you.<|endoftext|>\"\n",
            "\"<|startoftext|>You can never be really \"out in the open\" since the moon will rise for you.<|endoftext|>\"\n",
            "\"<|startoftext|>We could be the most paranoid species in the solar system and still have no record of humanity.<|endoftext|>\"\n",
            "\"<|startoftext|>I wonder if other animals see us like a virus that infects their system and makes us unable to understand and understand what humans can do<|endoftext|>\"\n",
            "\"<|startoftext|>You can live forever and never meet anyone new, but no one will ever know for sure.<|endoftext|>\"\n",
            "\"<|startoftext|>If you're ever lonely because you are always alone, and you really are alone, why is there no internet?<|endoftext|>\"\n",
            "\"<|startoftext|>If you were a member of The Beatles they'd have been a great time-traveler<|endoftext|>\"\n",
            "\"<|startoftext|>Why was the original '80s video the original '90s video?<|endoftext|>\"\n",
            "\"<|startoftext|>The fact that the word ‘shower’ can't be ‘in’ only makes it more awkward that one of the most common words for ‘shower’ has negative connotations<|endoftext|>\"\n",
            "\"<|startoftext|>Insecticidal maniacs would probably be the least of your worries if it wasn't for them being next to invincible.<|endoftext|>\"\n",
            "\"<|startoftext|>I know it's weird but if you had enough space you could just get a nuclear bomb somewhere you’d want one.<|endoftext|>\"\n",
            "\"<|startoftext|>If the universe had ended in a parallel universe Earth would probably be pretty messed up.<|endoftext|>\"\n",
            "\"<|startoftext|>You can live forever and never meet anyone new, but no one will ever know for sure.<|endoftext|>\"\n",
            "\"<|startoftext|>When we vaccinate people we are giving them the ultimate gift that will outlive our entire life: the feeling of like they are the last person alive on earth, and like they are the last person on earth all of eternity.<|endoftext|>\"\n",
            "\"<|startoftext|>If you have a second by second record of the last time you played an instrument, you'll never be better than the person who owned that second in the first place.<|endoftext|>\"\n",
            "\"<|startoftext|>Asking a simple question can make you think about a lot of things.<|endoftext|>\"\n",
            "\"<|startoftext|>The more I think about brain cancer the more I realize that the tumor is in such a small amount of your brain.<|endoftext|>\"\n",
            "\"<|startoftext|>A broken clock is right once a day for the past, but not once each day for future.<|endoftext|>\"\n",
            "\"<|startoftext|>The name ‘santa’ was invented by a famous man but the brain used the name ‘santa’ in its original meaning of a man in a strange place.<|endoftext|>\"\n",
            "\"<|startoftext|>The most common word for “santa” hasn’t changed in over 70 years<|endoftext|>\"\n",
            "\"<|startoftext|>If you've read every book and you have\n",
            "\n",
            "[1410 | 1377.48] loss=1.38 avg=1.70\n",
            "[1420 | 1386.28] loss=1.47 avg=1.70\n",
            "[1430 | 1395.07] loss=1.88 avg=1.70\n",
            "[1440 | 1403.87] loss=1.48 avg=1.70\n",
            "[1450 | 1412.67] loss=1.51 avg=1.70\n",
            "[1460 | 1421.47] loss=1.74 avg=1.70\n",
            "[1470 | 1430.27] loss=1.41 avg=1.69\n",
            "[1480 | 1439.07] loss=1.74 avg=1.69\n",
            "[1490 | 1447.87] loss=1.29 avg=1.69\n",
            "[1500 | 1456.67] loss=1.39 avg=1.68\n",
            "Saving checkpoint/run1/model-1500\n",
            "[1510 | 1471.29] loss=1.99 avg=1.69\n",
            "[1520 | 1480.08] loss=2.03 avg=1.69\n",
            "[1530 | 1488.88] loss=1.46 avg=1.69\n",
            "[1540 | 1497.69] loss=0.87 avg=1.68\n",
            "[1550 | 1506.49] loss=1.48 avg=1.68\n",
            "[1560 | 1515.29] loss=0.82 avg=1.67\n",
            "[1570 | 1524.09] loss=2.09 avg=1.67\n",
            "[1580 | 1532.88] loss=1.83 avg=1.67\n",
            "[1590 | 1541.68] loss=2.10 avg=1.68\n",
            "[1600 | 1550.48] loss=0.97 avg=1.67\n",
            "======== SAMPLE 1 ========\n",
            " streter<|endoftext|>\"\n",
            "\"<|startoftext|>One day humans will look at other species and see the different ways other species have attempted to exploit that same vulnerability we all have.<|endoftext|>\"\n",
            "\"<|startoftext|>The only thing faster than the speed of sound is the thought of sound.<|endoftext|>\"\n",
            "\"<|startoftext|>There could very well have been a species that found out what they were doing and evolved to be stealthy, undetected assassins. There are so many amazing things about how mammals and birds are portrayed in media that we could be assassinating our loved ones by doing the exact same tasks and looking the same way.<|endoftext|>\"\n",
            "\"<|startoftext|>Every day in your life is your OWN personal time capsule and we are all just random strangers.<|endoftext|>\"\n",
            "\"<|startoftext|>Everyone is entitled to their own opinion but everyone has the right to speak what everyone feels is true.<|endoftext|>\"\n",
            "\"<|startoftext|>Do you ever just sit there and observe or do you ever just speak your minds mindfully and make little inferences?<|endoftext|>\"\n",
            "\"<|startoftext|>We're all crazy, crazy people, just like the guy who died last year in a car wreck<|endoftext|>\"\n",
            "\"<|startoftext|>There is a difference between eating and drinking and both involve pain.<|endoftext|>\"\n",
            "\"<|startoftext|>People who like cold food is the same people that like hot food so it makes sense why we eat and drink cold.<|endoftext|>\"\n",
            "\"<|startoftext|>The best person the world had to be to create the current climate is Donald J. Trump<|endoftext|>\"\n",
            "\"<|startoftext|>A lot of people love cold food, but no one loves hot food so technically it doesn't make sense to me<|endoftext|>\"\n",
            "\"<|startoftext|>The current state of the earth is causing it to get warmer and warmer.<|endoftext|>\"\n",
            "\"<|startoftext|>A ton of people will die in a car crash in the next 5 years because of a person with a different phone brand instead of a different model.<|endoftext|>\"\n",
            "\"<|startoftext|>We are all familiar with the concept of a shower thought, but what if we’re all just remembering the same shower thought?<|endoftext|>\"\n",
            "\"<|startoftext|>What if if someone had a mirror perfect shower and just had that thought on the spot?<|endoftext|>\"\n",
            "\"<|startoftext|>The most basic exercise is just standing still for no reason<|endoftext|>\"\n",
            "\"<|startoftext|>If my dog thinks its cute or not, I will take it to a park of any size, and we are both going to get a puppy.<|endoftext|>\"\n",
            "\"<|startoftext|>We like to think that all animals are innocent, innocent little beings. But innocent little bugs can easily be turned into criminal masterminds by being given the chance to walk in a specific direction or be rewarded based on their good behavior. Not so with other living things.<|endoftext|>\"\n",
            "\"<|startoftext|>We can’t imagine anything without color<|endoftext|>\"\n",
            "\"<|startoftext|>Most people have never heard the phrase \"\"smelling the scents of what’s in the air\"\"<|endoftext|>\"\n",
            "\"<|startoftext|>People are going to look at us funny this year for no good reason.<|endoftext|>\"\n",
            "\"<|startoftext|>Do people call each other dogs names just to make them mad or because they’re scared of each other? Or is it just because they’re scared of losing?<|endoftext|>\"\n",
            "\"<|startoftext|>I never thought about what the term \"\"loudspeaker\"\" sounded like until I was working at a music studio.<|endoftext|>\"\n",
            "\"<|startoftext|>When the universe is just one big computer, all the particles would be playing the same game.<|endoftext|>\"\n",
            "\"<|startoftext|>If everything on this earth is sentient, why do we only talk about the people we’ve killed, and never the people we’ve saved from extinction?<|endoftext|>\"\n",
            "\"<|startoftext|>Breathing is like sex, we only do it when we\n",
            "\n",
            "[1610 | 1575.02] loss=1.42 avg=1.67\n",
            "[1620 | 1583.82] loss=0.82 avg=1.66\n",
            "[1630 | 1592.62] loss=1.96 avg=1.66\n",
            "[1640 | 1601.41] loss=1.97 avg=1.66\n",
            "[1650 | 1610.21] loss=1.50 avg=1.66\n",
            "[1660 | 1619.00] loss=1.50 avg=1.66\n",
            "[1670 | 1627.80] loss=1.93 avg=1.66\n",
            "[1680 | 1636.60] loss=1.95 avg=1.67\n",
            "[1690 | 1645.40] loss=1.14 avg=1.66\n",
            "[1700 | 1654.20] loss=1.55 avg=1.66\n",
            "[1710 | 1663.00] loss=0.91 avg=1.65\n",
            "[1720 | 1671.79] loss=1.02 avg=1.64\n",
            "[1730 | 1680.61] loss=0.95 avg=1.63\n",
            "[1740 | 1689.44] loss=0.86 avg=1.62\n",
            "[1750 | 1698.23] loss=0.67 avg=1.61\n",
            "[1760 | 1707.04] loss=0.94 avg=1.60\n",
            "[1770 | 1715.83] loss=1.52 avg=1.60\n",
            "[1780 | 1724.63] loss=1.45 avg=1.60\n",
            "[1790 | 1733.43] loss=0.85 avg=1.59\n",
            "[1800 | 1742.23] loss=1.58 avg=1.59\n",
            "======== SAMPLE 1 ========\n",
            " same is my wife. But she can choose whether or not to have me.<|endoftext|>\"\n",
            "\"<|startoftext|>If you're the biggest douche in the world, it’s not because of your penis, it’s just because of the power you have.<|endoftext|>\"\n",
            "\"<|startoftext|>I wonder what the next generation will think of mocks and jokes.<|endoftext|>\"\n",
            "\"<|startoftext|>At this particular moment in time, there's probably an alien race already looking at Earth with their eyes peeping up from under their bonnets<|endoftext|>\"\n",
            "\"<|startoftext|>Your body isn’t really a human being, but a computer brain is.<|endoftext|>\"\n",
            "\"<|startoftext|>Every time you lie, you’re saying \"\"you’re telling the truth\"\"<|endoftext|>\"\n",
            "\"<|startoftext|>If a computer doesn’t have batteries, what makes it “computer?”<|endoftext|>\"\n",
            "\"<|startoftext|>The reason that you get one hit point when you can do 5, is probably because the opponent has more hit points than you<|endoftext|>\"\n",
            "\"<|startoftext|>This would be the best time to get a nose job.<|endoftext|>\"\n",
            "\"<|startoftext|>AIs from AI Dungeon 2 to sexy to funny and one based wholly on Reddit!<|endoftext|>\"\n",
            "\"<|startoftext|>When your mom says, “It’s fine, I'll cook for you” it makes perfect sense to her, but it’s totally weird to you.<|endoftext|>\"\n",
            "\"<|startoftext|>(Nsfw) Why are there a million dollars worth of eBay items that I can’t post in a store??<|endoftext|>\"\n",
            "\"<|startoftext|>Crocodile eggs are a human Easter Egg.<|endoftext|>\"\n",
            "\"<|startoftext|>People who make and sell Halloween masks are now laundering their cash.<|endoftext|>\"\n",
            "\"<|startoftext|>Why do people make and sell Halloween masks?<|endoftext|>\"\n",
            "\"<|startoftext|>If spiders' legs were big enough, I imagine spiders' whole appearance would be horrifying<|endoftext|>\"\n",
            "\"<|startoftext|>I've probably met an actor who is just now starting to realize their character has become more and more boring since they've started doing a series of boring things in the past.<|endoftext|>\"\n",
            "\"<|startoftext|>If spiders' legs were big enough, would spiders' whole appearance be horrifying?<|endoftext|>\"\n",
            "\"<|startoftext|>You are not only closer to a million dollars than Jeff Bezos, you are closer to having a billion dollars than Jeff Bezos<|endoftext|>\"\n",
            "\"<|startoftext|>If you're reading this and looking, do not say “my god” to tell us that there is not an equivalent word to that word in English, but a word that means god and that the other language is the right language with our word for that word would be the answer.<|endoftext|>\"\n",
            "\"<|startoftext|>If a robot gets lost in the underwater world and their primary language is another language and they are playing robot matches do they still know English and still play robot<|endoftext|>\"\n",
            "\"<|startoftext|>In space, you’re not actually alone anymore. Everybody’s a giant toilet.<|endoftext|>\"\n",
            "\"<|startoftext|>if humans were able to evolve into something other than a bunch of herbivores, the herbivores would go extinct.<|endoftext|>\"\n",
            "\"<|startoftext|>If you have a comment section you do not have to do anything to please it.<|endoftext|>\"\n",
            "\"<|startoftext|>If humans were able to evolve into something other than a bunch of herbivores. Did the herbivores go extinct?<|endoftext|>\"\n",
            "\"<|startoftext|>There is probably a planet right now that is so cold its thermostat doesn't want us here because it uses the sun to measure the temperature.<|endoftext|>\"\n",
            "\"<|startoftext|>A dog is always a dog no matter what you call them.<|endoftext|>\"\n",
            "\"<|startoftext|>\n",
            "\n",
            "[1810 | 1766.74] loss=1.64 avg=1.59\n",
            "[1820 | 1775.53] loss=1.10 avg=1.59\n",
            "[1830 | 1784.33] loss=0.94 avg=1.58\n",
            "[1840 | 1793.13] loss=1.32 avg=1.58\n",
            "[1850 | 1801.93] loss=1.52 avg=1.58\n",
            "[1860 | 1810.73] loss=2.03 avg=1.58\n",
            "[1870 | 1819.52] loss=1.38 avg=1.58\n",
            "[1880 | 1828.32] loss=1.18 avg=1.57\n",
            "[1890 | 1837.12] loss=1.87 avg=1.58\n",
            "[1900 | 1845.91] loss=0.83 avg=1.57\n",
            "[1910 | 1854.71] loss=1.41 avg=1.57\n",
            "[1920 | 1863.50] loss=1.35 avg=1.56\n",
            "[1930 | 1872.30] loss=1.64 avg=1.56\n",
            "[1940 | 1881.10] loss=2.29 avg=1.57\n",
            "[1950 | 1889.90] loss=1.27 avg=1.57\n",
            "[1960 | 1898.70] loss=1.23 avg=1.57\n",
            "[1970 | 1907.50] loss=1.05 avg=1.56\n",
            "[1980 | 1916.30] loss=1.44 avg=1.56\n",
            "[1990 | 1925.10] loss=1.01 avg=1.55\n",
            "[2000 | 1933.90] loss=0.85 avg=1.54\n",
            "Saving checkpoint/run1/model-2000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IXSuTNERaw6K",
        "colab_type": "text"
      },
      "source": [
        "After the model is trained, you can copy the checkpoint folder to your own Google Drive.\n",
        "\n",
        "If you want to download it to your personal computer, it's strongly recommended you copy it there first, then download from Google Drive. The checkpoint folder is copied as a `.rar` compressed file; you can download it and uncompress it locally."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VHdTL8NDbAh3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "outputId": "747142ea-87c6-4e18-e1a6-06d58e8b2683"
      },
      "source": [
        "gpt2.copy_checkpoint_to_gdrive(run_name='run2')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-da75eceb454d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgpt2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_checkpoint_to_gdrive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'run2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gpt_2_simple/gpt_2.py\u001b[0m in \u001b[0;36mcopy_checkpoint_to_gdrive\u001b[0;34m(run_name, copy_folder)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0;31m# Reference: https://stackoverflow.com/a/17081026\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtarfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m             \u001b[0mtar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m         \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopyfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"/content/drive/My Drive/\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/tarfile.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, name, arcname, recursive, exclude, filter)\u001b[0m\n\u001b[1;32m   1936\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1937\u001b[0m         \u001b[0;31m# Create a TarInfo object from the file.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1938\u001b[0;31m         \u001b[0mtarinfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgettarinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marcname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1939\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1940\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtarinfo\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/tarfile.py\u001b[0m in \u001b[0;36mgettarinfo\u001b[0;34m(self, name, arcname, fileobj)\u001b[0m\n\u001b[1;32m   1805\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfileobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1806\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"lstat\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdereference\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1807\u001b[0;31m                 \u001b[0mstatres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1808\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1809\u001b[0m                 \u001b[0mstatres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'checkpoint/run2'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qQJgV_b4bmzd",
        "colab_type": "text"
      },
      "source": [
        "You're done! Feel free to go to the **Generate Text From The Trained Model** section to generate text based on your retrained model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pel-uBULXO2L",
        "colab_type": "text"
      },
      "source": [
        "## Load a Trained Model Checkpoint\n",
        "\n",
        "Running the next cell will copy the `.rar` checkpoint file from your Google Drive into the Colaboratory VM."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DCcx5u7sbPTD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gpt2.copy_checkpoint_from_gdrive(run_name='run1')"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RTa6zf3e_9gV",
        "colab_type": "text"
      },
      "source": [
        "The next cell will allow you to load the retrained model checkpoint + metadata necessary to generate text.\n",
        "\n",
        "**IMPORTANT NOTE:** If you want to rerun this cell, **restart the VM first** (Runtime -> Restart Runtime). You will need to rerun imports but not recopy files."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-fxL77nvAMAX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sess = gpt2.start_tf_sess()\n",
        "gpt2.load_gpt2(sess, run_name='run1')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ClJwpF_ACONp",
        "colab_type": "text"
      },
      "source": [
        "## Generate Text From The Trained Model\n",
        "\n",
        "After you've trained the model or loaded a retrained model from checkpoint, you can now generate text. `generate` generates a single text from the loaded model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4RNY6RBI9LmL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "outputId": "1974220b-68c8-46d5-a4b5-47c7399bdba1"
      },
      "source": [
        "gpt2.generate(sess, run_name='run1')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\"<|startoftext|>If you give yourself a one-time password, you can never get it to work again.<|endoftext|>\"\n",
            "\"<|startoftext|>After all this shit settles down we'll have a lot of new president candidates.<|endoftext|>\"\n",
            "\"<|startoftext|>With how things are going now, the 2020 election is a lot closer than we think.<|endoftext|>\"\n",
            "\"<|startoftext|>What if the future of the universe is just a simulation and we are the simulation.<|endoftext|>\"\n",
            "\"<|startoftext|>If you give yourself a one-time password, you can never get it to work again.<|endoftext|>\"\n",
            "\"<|startoftext|>We will have a lot of new president candidates in 2020<|endoftext|>\"\n",
            "\"<|startoftext|>The future of the universe is simulation, and we are the simulation.<|endoftext|>\"\n",
            "\"<|startoftext|>Everyone has the right amount of glasses. You only need the right glasses for the right thing. That doesn't mean you need glasses for everything.<|endoftext|>\"\n",
            "\"<|startoftext|>The concept of a “privilege or disadvantage” is arbitrary<|endoftext|>\"\n",
            "\"<|startoftext|>You can never have your cake and eat it too, because it is already taken.<|endoftext|>\"\n",
            "\"<|startoftext|>You have never seen an actual person fart and there has never been a real person fart<|endoftext|>\"\n",
            "\"<|startoftext|>Your opinions are more valuable than mine, because you don't have to listen to what I have to say<|endoftext|>\"\n",
            "\"<|startoftext|>The newly released \"\"All or Nothing\"\" album is a great example of a bandcamp that is not made by a bandcamp.<|endoftext|>\"\n",
            "\"<|startoftext|>The sun produces energy through nuclear fission and energy cannot be created nor destroyed but can be captured and used as energy.<|endoftext|>\"\n",
            "\"<|startoftext|>You can never have your cake and eat it too, because it is already taken.<|endoftext|>\"\n",
            "\"<|startoftext|>You can never have your cake and eat it too. That's why you are not allowed to eat it too.<|endoftext|>\"\n",
            "<|startoftext|>Water<|endoftext|>\n",
            "\"<|startoftext|>If your pee hole has a hole in it, it's probably a shit hole.<|endoftext|>\"\n",
            "\"<|startoftext|>We are to the moon as a human balloon and the earth as a human balloon<|endoftext|>\"\n",
            "\"<|startoftext|>The sun produces energy with nuclear fission and energy cannot be created nor destroyed but can be captured and used as energy.<|endoftext|>\"\n",
            "\"<|startoftext|>The newly released \"\"All or Nothing\"\" album is a great example of a bandcamp that is not made by a bandcamp.<|endoftext|>\"\n",
            "\"<|startoftext|>If our arm, leg, back, and chest hair is on fire, is it a fire in the shower?<|endoftext|>\"\n",
            "\"<|startoftext|>You can never have your cake and eat it too, because it is already taken.<|endoftext|>\"\n",
            "\"<|startoftext|>The new president is the first president ever to have his or her head shaved<|endoftext|>\"\n",
            "\"<|startoftext|>2020 is the closest we've ever been to a post-apocalyptic world<|endoftext|>\"\n",
            "\"<|startoftext|>The new president is the first person ever to have his or her head shaved<|endoftext|>\"\n",
            "\"<|startoftext|>The new president is the first person ever to have his or her head shaved<|endoftext|>\"\n",
            "\"<|startoftext|>The new president is the first person ever to have his or her head shaved<|endoftext|>\"\n",
            "\"<|startoftext|>While selfies are going to be the norm a while, old school photos will be the norm forever<|endoftext|>\"\n",
            "\"<|startoftext|>Being a good reader is like being an actor on screen<|endoftext|>\"\n",
            "\"<|startoftext|>You either become an imposter or become an actor/musician/actress/whatever that lives in\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oF4-PqF0Fl7R",
        "colab_type": "text"
      },
      "source": [
        "If you're creating an API based on your model and need to pass the generated text elsewhere, you can do `text = gpt2.generate(sess, return_as_list=True)[0]`\n",
        "\n",
        "You can also pass in a `prefix` to the generate function to force the text to start with a given character sequence and generate text from there (good if you add an indicator when the text starts).\n",
        "\n",
        "You can also generate multiple texts at a time by specifing `nsamples`. Unique to GPT-2, you can pass a `batch_size` to generate multiple samples in parallel, giving a massive speedup (in Colaboratory, set a maximum of 20 for `batch_size`).\n",
        "\n",
        "Other optional-but-helpful parameters for `gpt2.generate` and friends:\n",
        "\n",
        "*  **`length`**: Number of tokens to generate (default 1023, the maximum)\n",
        "* **`temperature`**: The higher the temperature, the crazier the text (default 0.7, recommended to keep between 0.7 and 1.0)\n",
        "* **`top_k`**: Limits the generated guesses to the top *k* guesses (default 0 which disables the behavior; if the generated output is super crazy, you may want to set `top_k=40`)\n",
        "* **`top_p`**: Nucleus sampling: limits the generated guesses to a cumulative probability. (gets good results on a dataset with `top_p=0.9`)\n",
        "* **`truncate`**: Truncates the input text until a given sequence, excluding that sequence (e.g. if `truncate='<|endoftext|>'`, the returned text will include everything before the first `<|endoftext|>`). It may be useful to combine this with a smaller `length` if the input texts are short.\n",
        "*  **`include_prefix`**: If using `truncate` and `include_prefix=False`, the specified `prefix` will not be included in the returned text."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8DKMc0fiej4N",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "e4a4d890-ed65-451d-b80c-c36a73db6ba8"
      },
      "source": [
        "gpt2.generate(sess,\n",
        "              length=750,\n",
        "              temperature=0.7,\n",
        "              prefix=\"Computers\",\n",
        "              # nsamples=5,\n",
        "              # batch_size=5\n",
        "              )"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Computers have found that the advance of black hole candidates is a maturing processfor star-forming stars, with the peak of the stellar evolution coming late in the gaseouspast. The black hole candidates are found to be typical of C/D stars, with a lowerprobability for C/D stars. Our results suggest that stars are major sources ofthe observed radio-loud X-ray emission, but we cannot exclude the possibility that theobservations are a combination of starlight and X-ray background. (abridgedabstract)<|endoftext|>\"\n",
            "\"<|startoftext|>  We present a detailed investigation of the thermal emission line fluxes ofdynamical systems in 20 quadrupeds. The spectra were taken from the VIIRS-N-band ata frequency of 1.5 GHz with the Dresden Axed Camera(XAC) and the Maxima Transient Camera (MAX) simultaneously and the spectrographswere taken simultaneously with the CCD camera. For the X-ray emission lines, we have estimatedthe extent of the continuum regions and found that they areflat on the sky. The continuum fluxes are consistent with ATCA (1.7 +/- 0.5 um) emission lines,although the continuum line fluxes have a significantly lower value of 0.7 um.The continuum fluxes are also consistent with the X-ray continuum fluxes ofall 6 stars. The continuum fluxes are best described by a variety of models,that include changes in the mass-to-light ratio, which produce aflat continuum flux.  The spectral energy distribution of the systems is characterized by a flat spectralenergy distribution (SED) with a broad but symmetric band. The spectralenergy distribution is similar to that of the hot X-ray systems, although the spectral energydistribution of the hot systems is pretty flat and the spectral energy distribution ofthe cold systems is much more complex.  The temperature of the systems is found to be independent of the mass of thesystem. The energy density of the systems is found to be independent of the massof the systems. The mass-to-light ratio of the systems is found to be independent ofthe mass of the systems. The spectral energy distribution differs greatlywith the temperature. The spectrum is similar to that of thehot systems and shows a high spectral energy distribution,with a broad and unbalanced spectral energy distribution and aflat spectral energy distribution. The spectral energy distribution and spectralenergy distribution are well described by a combination of a simple stellar population modeland a single-celled model. The spectral energy distribution of thehot and cold systems is characterized by a small (10<V<18) to large (50<V<100) spectralenergy distribution with a 3.6 kpc energy resolution. The spectral energydistribution of the hot systems is well described by a simple stellar population model and asingle-celled model.<|endoftext|>\"\n",
            "\"<|startoftext|>  ATIS experiments detect CO in the C/O-rich clouds of the Galactic disk. The CO-rich cloudsare inhospitable for the CO-rich star formation process leading to the formationof the CO-rich star. Here we describe the CO discovery in the CO-rich clouds ofthe Galactic disk and examine the possibility that these clouds could be the source of the CO-richstar. We hypothesize that the CO-rich cloud could be the CO-rich star,therefore the CO-rich clouds could be the carbon source of the star and the CO-rich cloudscould be the CO-rich stars. The presence of CO in CO-rich\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zjjEN2Tafhl2",
        "colab_type": "text"
      },
      "source": [
        "For bulk generation, you can generate a large amount of text to a file and sort out the samples locally on your computer. The next cell will generate a generated text file with a unique timestamp.\n",
        "\n",
        "You can rerun the cells as many times as you want for even more generated texts!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fa6p6arifSL0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gen_file = 'gpt2_gentext_{:%Y%m%d_%H%M%S}.txt'.format(datetime.utcnow())\n",
        "\n",
        "gpt2.generate_to_file(sess,\n",
        "                      destination_path=gen_file,\n",
        "                      length=500,\n",
        "                      temperature=0.7,\n",
        "                      nsamples=100,\n",
        "                      batch_size=20\n",
        "                      )"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-LRex8lfv1g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "d3e86e73-311b-480f-b081-98cc92e231c8"
      },
      "source": [
        "# may have to run twice to get file to download\n",
        "files.download(gen_file)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_ab6c3008-72c9-4416-bb74-406114c1dd9b\", \"gpt2_gentext_20200921_011729.txt\", 165766)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wmTXWNUygS5E",
        "colab_type": "text"
      },
      "source": [
        "# LICENSE\n",
        "\n",
        "MIT License\n",
        "\n",
        "Copyright (c) 2019 Max Woolf\n",
        "\n",
        "Permission is hereby granted, free of charge, to any person obtaining a copy\n",
        "of this software and associated documentation files (the \"Software\"), to deal\n",
        "in the Software without restriction, including without limitation the rights\n",
        "to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
        "copies of the Software, and to permit persons to whom the Software is\n",
        "furnished to do so, subject to the following conditions:\n",
        "\n",
        "The above copyright notice and this permission notice shall be included in all\n",
        "copies or substantial portions of the Software.\n",
        "\n",
        "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
        "IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
        "FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
        "AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
        "LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
        "OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
        "SOFTWARE."
      ]
    }
  ]
}